{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Installs"
      ],
      "metadata": {
        "id": "Ty8YP4TNd3SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s27QlAzX_Qt7",
        "outputId": "6d5c62f2-44e0-4bf1-f4b2-97fcebe3efa2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=4584538e1226e53698e76359b9c4ee872e843c00ddc632c81006488a852c5c3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.22.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPue4B2vPu2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577c4d6b-c5d3-4a91-d78b-a7479008d6c2"
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "import torch.profiler\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "from torchvision import datasets \n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "# calculate train time, writing train data to files etc.\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "import math\n",
        "import copy\n",
        "from IPython.display import clear_output\n",
        "from time import perf_counter\n",
        "from torch.autograd import Variable\n",
        "torch.set_printoptions(linewidth=120)\n",
        "torch.set_grad_enabled(True)     # On by default, leave it here for clarity"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7feddbe63e50>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "metadata": {
        "id": "CesBIiQHQYRL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn"
      ],
      "metadata": {
        "id": "y5Av6YqnssFz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "xQOmyV5ruNf9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iDlvtrBQZO3",
        "outputId": "1f10200b-9db1-44b4-fb56-832afe3bb4f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check PyTorch versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n",
            "0.15.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "CojWu8cMDc-j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging into WandB\n"
      ],
      "metadata": {
        "id": "kaAPJzOC_cCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "TehLE0Z5_fxY",
        "outputId": "f06f841c-7028-485b-a9b0-f4084b20581c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset\n"
      ],
      "metadata": {
        "id": "XzxFyYxad71T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "xHh1pvf9eUFw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = torchvision.datasets.CIFAR10('./data', download=True, train=True, transform=train_transforms)\n",
        "\n",
        "# Download and load the test set\n",
        "dataset_test = torchvision.datasets.CIFAR10('./data', download=True, train=False, transform=test_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f80994-b647-4424-efbf-9f81d72d6419",
        "id": "ak2BBC1oQpb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 82067544.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, valset = torch.utils.data.random_split(dataset_train, [40000, 10000])\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(dataset_test, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "H_0f-XwTQpb1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set cuda to device"
      ],
      "metadata": {
        "id": "W9gpIza6eIME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.cuda.memory_summary(device=None, abbreviated=True)"
      ],
      "metadata": {
        "id": "i5xtz8_DZBq8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wHJbL98ZY5mg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSi_tn2rOSKl",
        "outputId": "e3e5071c-6e4a-4fa4-b2c9-d009962cef72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Some key definitions"
      ],
      "metadata": {
        "id": "Nsyem3b0eQSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count of correct predictions"
      ],
      "metadata": {
        "id": "8ozaaWJ7eXmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_test_predictions(images, labels, outputs, predicted, test_table, log_counter):\n",
        "  # obtain confidence scores for all classes\n",
        "  scores = F.softmax(outputs.data, dim=1)\n",
        "  log_scores = scores.cpu().numpy()\n",
        "  log_images = images.cpu().numpy()\n",
        "  log_labels = labels.cpu().numpy()\n",
        "  log_preds = predicted.cpu().numpy()\n",
        "  # adding ids based on the order of the images\n",
        "  _id = 0\n",
        "  for i, l, p, s in zip(log_images, log_labels, log_preds, log_scores):\n",
        "    # add required info to data table:\n",
        "    # id, image pixels, model's guess, true label, scores for all classes\n",
        "    img_id = str(_id) + \"_\" + str(log_counter)\n",
        "    test_table.add_data(img_id, wandb.Image(np.transpose(i, (1, 2, 0))), p, l, *s)\n",
        "    _id += 1\n",
        "    if _id == NUM_IMAGES_PER_BATCH:\n",
        "      break\n"
      ],
      "metadata": {
        "id": "87NTgyACpIDd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOe6m7forHCM"
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topk_correct(preds,labels,k=5):\n",
        "    batch_size = preds.shape[0]\n",
        "\n",
        "    # get the top-5 predictions for each sample\n",
        "    topk_values, topk_indices = torch.topk(preds, k=5, dim=1)\n",
        "\n",
        "    # check if the target is in the top-5 predictions\n",
        "    correct_topk = topk_indices.eq(labels.view(-1, 1).expand_as(topk_indices))\n",
        "    return correct_topk\n",
        "## calculate top-5 accuracy\n",
        "#top5_accuracy = correct_topk.float().sum() / batch_size"
      ],
      "metadata": {
        "id": "t6YaB1HBJkyu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## taking value of parameters and trying them in all combinations"
      ],
      "metadata": {
        "id": "jv8d5oYGecI4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBOxsN4A7N8K"
      },
      "source": [
        "# import modules to build RunBuilder and RunManager helper classes\n",
        "from collections  import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "\n",
        "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
        "# combinations of hyper-parameters\n",
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "\n",
        "    Run = namedtuple('Run', params.keys())\n",
        "\n",
        "    runs = []\n",
        "    for v in product(*params.values()):\n",
        "      runs.append(Run(*v))\n",
        "    \n",
        "    return runs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defining Manager class "
      ],
      "metadata": {
        "id": "Zyi8muZXeiMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helps in calculating both train and validation accuracy and losses also help us to maintain a tensorboard and print all the data collected for every epoch and save it in a dataset "
      ],
      "metadata": {
        "id": "DVo1Jq-ge0Oa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSddFGL7zisa"
      },
      "source": [
        "# Helper class, help track loss, accuracy, epoch time, run time, \n",
        "# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n",
        "class RunManager():\n",
        "  def __init__(self):\n",
        "\n",
        "    # tracking every epoch count, loss, accuracy, time\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_val_loss = 0\n",
        "    self.epoch_num_correct_train = 0\n",
        "    self.epoch_num_correct_test = 0\n",
        "    self.epoch_start_time = None\n",
        "\n",
        "    # tracking every run count, run data, hyper-params used, time\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "    self.run_start_time = None\n",
        "\n",
        "    # record model, loader and TensorBoard \n",
        "    self.network = None\n",
        "    self.trainloader = None\n",
        "    self.valloader = None\n",
        "    self.tb = None\n",
        "\n",
        "  # record the count, hyper-param, model, loader of each run\n",
        "  # record sample images and network graph to TensorBoard  \n",
        "  def begin_run(self, run, network, trainloader,valloader):\n",
        "\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.trainloader = trainloader\n",
        "    self.valloader = valloader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    wandb.init(\n",
        "        # set the wandb project where this run will be logged\n",
        "        project=\"dl_project_2023\",\n",
        "        \n",
        "        # track hyperparameters and run metadata\n",
        "        config={\n",
        "        \"learning_rate\": run.lr,\n",
        "        \"architecture\": run.arch,\n",
        "        \"dataset\": run.dataset,\n",
        "        \"epochs\": 30,\n",
        "        \"activation_function\":run.act_func,\n",
        "        \"Optimizer\":run.opt,\n",
        "        \"Regularisation\":run.reg\n",
        "        }\n",
        "    )\n",
        "    #images, labels = next(iter(self.trainloader))\n",
        "    #images, labels = images.to(device), labels.to(device)\n",
        "    #grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "    #self.tb.add_image('images', grid)\n",
        "    #self.tb.add_graph(self.network, images)\n",
        "\n",
        "  # when run ends, close TensorBoard, zero epoch count\n",
        "  def end_run(self):\n",
        "    wandb.finish()\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  # zero epoch count, loss, accuracy, \n",
        "  def begin_epoch(self):\n",
        "    self.epoch_start_time = time.time()\n",
        "\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_val_loss = 0\n",
        "    self.epoch_num_correct_train = 0\n",
        "    self.epoch_num_correct_test = 0\n",
        "    print(\"Training Epoch\",self.epoch_count)\n",
        "\n",
        "  # \n",
        "  def end_epoch(self):\n",
        "    # calculate epoch duration and run duration(accumulate)\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    # record epoch loss and accuracy\n",
        "    train_loss = self.epoch_loss / len(self.trainloader.dataset)\n",
        "    val_loss = self.epoch_val_loss / len(self.valloader.dataset)\n",
        "    train_accuracy = self.epoch_num_correct_train / len(self.trainloader.dataset)\n",
        "    test_accuracy = self.epoch_num_correct_test / len(self.valloader.dataset)\n",
        "    # Record epoch loss and accuracy to TensorBoard \n",
        "    self.tb.add_scalar('Train Loss', train_loss, self.epoch_count)\n",
        "    self.tb.add_scalar('train Accuracy', train_accuracy, self.epoch_count)\n",
        "    self.tb.add_scalar('Validation Loss', val_loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Validation Accuracy', test_accuracy, self.epoch_count)\n",
        "\n",
        "    # Record params to TensorBoard\n",
        "    #for name, param in self.network.named_parameters():\n",
        "      #self.tb.add_histogram(name, param, self.epoch_count)\n",
        "      #self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "    \n",
        "    # Write into 'results' (OrderedDict) for all run related data\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run_count\n",
        "    results[\"epoch\"] = self.epoch_count\n",
        "    results[\"train_loss\"] = train_loss\n",
        "    results[\"val_loss\"] = val_loss\n",
        "    results[\"train_accuracy\"] = train_accuracy\n",
        "    results[\"val_accuracy\"] = test_accuracy\n",
        "    results[\"epoch duration\"] = epoch_duration\n",
        "    results[\"run duration\"] = run_duration\n",
        "    print(\"train_acc = \", train_accuracy, \"train_loss = \", train_loss, \"Validation_acc = \", test_accuracy, \"Validation_loss = \", val_loss)\n",
        "    wandb.log({\"train_acc\": train_accuracy, \"train_loss\": train_loss, \"Validation_acc\": test_accuracy, \"Validation_loss\": val_loss})\n",
        "    \n",
        "    # Record hyper-params into 'results'\n",
        "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "    self.run_data.append(results)\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
        "\n",
        "    # display epoch information and show progress\n",
        "    # clear_output(wait=True)\n",
        "    # display(df)\n",
        "\n",
        "  # accumulate loss of batch into entire epoch loss\n",
        "  def track_loss(self, loss):\n",
        "    # multiply batch size so variety of batch sizes can be compared\n",
        "    self.epoch_loss += loss.item() * self.trainloader.batch_size\n",
        "  def track_val_loss(self, loss):\n",
        "    # multiply batch size so variety of batch sizes can be compared\n",
        "    self.epoch_val_loss += loss.item() * self.valloader.batch_size\n",
        "  # accumulate number of corrects of batch into entire epoch num_correct\n",
        "  def track_num_correct_train(self, preds, labels):\n",
        "    self.epoch_num_correct_train += self._get_num_correct(preds, labels)\n",
        "  def track_num_correct_test(self, preds, labels):\n",
        "    self.epoch_num_correct_test += self._get_num_correct(preds, labels)\n",
        "  @torch.no_grad()\n",
        "  def _get_num_correct(self, preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "  \n",
        "  # save end results of all runs into csv, json for further a\n",
        "  def save(self, fileName):\n",
        "\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data, \n",
        "        orient = 'columns',\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Shake Drop Regularisation\n"
      ],
      "metadata": {
        "id": "74WW3tEuOpjZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cl7bmnHfA8H8"
      },
      "outputs": [],
      "source": [
        "class ShakeDropFunction(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, training=True, p_drop=0.5, alpha_range=[-1, 1]):\n",
        "        if training:\n",
        "            gate = torch.cuda.FloatTensor([0]).bernoulli_(1 - p_drop)\n",
        "            ctx.save_for_backward(gate)\n",
        "            if gate.item() == 0:\n",
        "                alpha = torch.cuda.FloatTensor(x.size(0)).uniform_(*alpha_range)\n",
        "                alpha = alpha.view(alpha.size(0), 1, 1, 1).expand_as(x)\n",
        "                return alpha * x\n",
        "            else:\n",
        "                return x\n",
        "        else:\n",
        "            return (1 - p_drop) * x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        gate = ctx.saved_tensors[0]\n",
        "        if gate.item() == 0:\n",
        "            beta = torch.cuda.FloatTensor(grad_output.size(0)).uniform_(0, 1)\n",
        "            beta = beta.view(beta.size(0), 1, 1, 1).expand_as(grad_output)\n",
        "            beta = Variable(beta)\n",
        "            return beta * grad_output, None, None, None\n",
        "        else:\n",
        "            return grad_output, None, None, None\n",
        "\n",
        "\n",
        "class ShakeDrop(nn.Module):\n",
        "\n",
        "    def __init__(self, p_drop=0.5, alpha_range=[-1, 1]):\n",
        "        super(ShakeDrop, self).__init__()\n",
        "        self.p_drop = p_drop\n",
        "        self.alpha_range = alpha_range\n",
        "\n",
        "    def forward(self, x):\n",
        "        return ShakeDropFunction.apply(x, self.training, self.p_drop, self.alpha_range)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Network as per given Instructions"
      ],
      "metadata": {
        "id": "I7DYL7SCeMWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(reg):\n",
        "    model = torchvision.models.resnext50_32x4d(weights='DEFAULT')\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    model.fc =  nn.Sequential(nn.Linear(2048, 1000),\n",
        "                                   nn.Linear(1000, 10))\n",
        "    if reg == 'shake-drop':\n",
        "        # model.relu = nn.Sequential(ShakeDrop(0.5),\n",
        "        #                             nn.ReLU())\n",
        "        # print(model.relu)\n",
        "        model.layer1[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                    ShakeDrop(0.2))\n",
        "\n",
        "        model.layer2[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                    ShakeDrop(0.2))\n",
        "\n",
        "        model.layer3[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                    ShakeDrop(0.2))\n",
        "\n",
        "        model.layer4[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                        ShakeDrop(0.2))\n",
        "        return model\n",
        "    elif reg == 'dropout':\n",
        "        # model.relu = nn.Sequential(nn.Dropout(p=0.2),\n",
        "        #                             nn.ReLU())\n",
        "        # print(model.relu)\n",
        "        model.layer1[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                    nn.Dropout(p=0.2))\n",
        "\n",
        "        model.layer2[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                    nn.Dropout(p=0.2))\n",
        "\n",
        "        model.layer3[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                    nn.Dropout(p=0.2))\n",
        "\n",
        "        model.layer4[0].relu = nn.Sequential(nn.ReLU(),\n",
        "                                                        nn.Dropout(p=0.2))\n",
        "        return model\n",
        "        # model.layer1[0].conv1 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "        #                                     nn.Dropout(p=0.2))\n",
        "        # model.layer2[0].conv1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
        "        #                                     nn.Dropout(p=0.2))\n",
        "        # model.layer3[0].conv1 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
        "        #                                     nn.Dropout(p=0.2))\n",
        "        # model.layer4[0].conv1 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
        "        #                                     nn.Dropout(p=0.2))\n",
        "        # return model\n",
        "    else:\n",
        "        return model"
      ],
      "metadata": {
        "id": "PJgnbwgeCgHG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model('shake-drop').to(device)\n",
        "summary(model, ( 3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Q71Z5rPcVh",
        "outputId": "c5c18f2b-528f-481e-c6a3-e442a58e4ec3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-1a0047aa.pth\n",
            "100%|██████████| 95.8M/95.8M [00:06<00:00, 16.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5            [-1, 128, 8, 8]           8,192\n",
            "       BatchNorm2d-6            [-1, 128, 8, 8]             256\n",
            "              ReLU-7            [-1, 128, 8, 8]               0\n",
            "         ShakeDrop-8            [-1, 128, 8, 8]               0\n",
            "            Conv2d-9            [-1, 128, 8, 8]           4,608\n",
            "      BatchNorm2d-10            [-1, 128, 8, 8]             256\n",
            "             ReLU-11            [-1, 128, 8, 8]               0\n",
            "        ShakeDrop-12            [-1, 128, 8, 8]               0\n",
            "           Conv2d-13            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "           Conv2d-15            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "        ShakeDrop-18            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-19            [-1, 256, 8, 8]               0\n",
            "           Conv2d-20            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
            "             ReLU-22            [-1, 128, 8, 8]               0\n",
            "        ShakeDrop-23            [-1, 128, 8, 8]               0\n",
            "           Conv2d-24            [-1, 128, 8, 8]           4,608\n",
            "      BatchNorm2d-25            [-1, 128, 8, 8]             256\n",
            "             ReLU-26            [-1, 128, 8, 8]               0\n",
            "        ShakeDrop-27            [-1, 128, 8, 8]               0\n",
            "           Conv2d-28            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-29            [-1, 256, 8, 8]             512\n",
            "             ReLU-30            [-1, 256, 8, 8]               0\n",
            "        ShakeDrop-31            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-32            [-1, 256, 8, 8]               0\n",
            "           Conv2d-33            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-34            [-1, 128, 8, 8]             256\n",
            "             ReLU-35            [-1, 128, 8, 8]               0\n",
            "        ShakeDrop-36            [-1, 128, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]           4,608\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "             ReLU-39            [-1, 128, 8, 8]               0\n",
            "        ShakeDrop-40            [-1, 128, 8, 8]               0\n",
            "           Conv2d-41            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-42            [-1, 256, 8, 8]             512\n",
            "             ReLU-43            [-1, 256, 8, 8]               0\n",
            "        ShakeDrop-44            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-45            [-1, 256, 8, 8]               0\n",
            "           Conv2d-46            [-1, 256, 8, 8]          65,536\n",
            "      BatchNorm2d-47            [-1, 256, 8, 8]             512\n",
            "             ReLU-48            [-1, 256, 8, 8]               0\n",
            "        ShakeDrop-49            [-1, 256, 8, 8]               0\n",
            "           Conv2d-50            [-1, 256, 4, 4]          18,432\n",
            "      BatchNorm2d-51            [-1, 256, 4, 4]             512\n",
            "             ReLU-52            [-1, 256, 4, 4]               0\n",
            "        ShakeDrop-53            [-1, 256, 4, 4]               0\n",
            "           Conv2d-54            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-56            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-58            [-1, 512, 4, 4]               0\n",
            "        ShakeDrop-59            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-60            [-1, 512, 4, 4]               0\n",
            "           Conv2d-61            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-62            [-1, 256, 4, 4]             512\n",
            "             ReLU-63            [-1, 256, 4, 4]               0\n",
            "        ShakeDrop-64            [-1, 256, 4, 4]               0\n",
            "           Conv2d-65            [-1, 256, 4, 4]          18,432\n",
            "      BatchNorm2d-66            [-1, 256, 4, 4]             512\n",
            "             ReLU-67            [-1, 256, 4, 4]               0\n",
            "        ShakeDrop-68            [-1, 256, 4, 4]               0\n",
            "           Conv2d-69            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-70            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-71            [-1, 512, 4, 4]               0\n",
            "        ShakeDrop-72            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-73            [-1, 512, 4, 4]               0\n",
            "           Conv2d-74            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-75            [-1, 256, 4, 4]             512\n",
            "             ReLU-76            [-1, 256, 4, 4]               0\n",
            "        ShakeDrop-77            [-1, 256, 4, 4]               0\n",
            "           Conv2d-78            [-1, 256, 4, 4]          18,432\n",
            "      BatchNorm2d-79            [-1, 256, 4, 4]             512\n",
            "             ReLU-80            [-1, 256, 4, 4]               0\n",
            "        ShakeDrop-81            [-1, 256, 4, 4]               0\n",
            "           Conv2d-82            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-83            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-84            [-1, 512, 4, 4]               0\n",
            "        ShakeDrop-85            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-86            [-1, 512, 4, 4]               0\n",
            "           Conv2d-87            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-88            [-1, 256, 4, 4]             512\n",
            "             ReLU-89            [-1, 256, 4, 4]               0\n",
            "        ShakeDrop-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]          18,432\n",
            "      BatchNorm2d-92            [-1, 256, 4, 4]             512\n",
            "             ReLU-93            [-1, 256, 4, 4]               0\n",
            "        ShakeDrop-94            [-1, 256, 4, 4]               0\n",
            "           Conv2d-95            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-96            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-97            [-1, 512, 4, 4]               0\n",
            "        ShakeDrop-98            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-99            [-1, 512, 4, 4]               0\n",
            "          Conv2d-100            [-1, 512, 4, 4]         262,144\n",
            "     BatchNorm2d-101            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-102            [-1, 512, 4, 4]               0\n",
            "       ShakeDrop-103            [-1, 512, 4, 4]               0\n",
            "          Conv2d-104            [-1, 512, 2, 2]          73,728\n",
            "     BatchNorm2d-105            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-106            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-107            [-1, 512, 2, 2]               0\n",
            "          Conv2d-108           [-1, 1024, 2, 2]         524,288\n",
            "     BatchNorm2d-109           [-1, 1024, 2, 2]           2,048\n",
            "          Conv2d-110           [-1, 1024, 2, 2]         524,288\n",
            "     BatchNorm2d-111           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-112           [-1, 1024, 2, 2]               0\n",
            "       ShakeDrop-113           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-114           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-115            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-116            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-117            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-118            [-1, 512, 2, 2]               0\n",
            "          Conv2d-119            [-1, 512, 2, 2]          73,728\n",
            "     BatchNorm2d-120            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-121            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-122            [-1, 512, 2, 2]               0\n",
            "          Conv2d-123           [-1, 1024, 2, 2]         524,288\n",
            "     BatchNorm2d-124           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-125           [-1, 1024, 2, 2]               0\n",
            "       ShakeDrop-126           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-127           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-128            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-129            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-130            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-131            [-1, 512, 2, 2]               0\n",
            "          Conv2d-132            [-1, 512, 2, 2]          73,728\n",
            "     BatchNorm2d-133            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-134            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-135            [-1, 512, 2, 2]               0\n",
            "          Conv2d-136           [-1, 1024, 2, 2]         524,288\n",
            "     BatchNorm2d-137           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-138           [-1, 1024, 2, 2]               0\n",
            "       ShakeDrop-139           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-143            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-144            [-1, 512, 2, 2]               0\n",
            "          Conv2d-145            [-1, 512, 2, 2]          73,728\n",
            "     BatchNorm2d-146            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-147            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-148            [-1, 512, 2, 2]               0\n",
            "          Conv2d-149           [-1, 1024, 2, 2]         524,288\n",
            "     BatchNorm2d-150           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-151           [-1, 1024, 2, 2]               0\n",
            "       ShakeDrop-152           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-153           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-154            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-155            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-156            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-157            [-1, 512, 2, 2]               0\n",
            "          Conv2d-158            [-1, 512, 2, 2]          73,728\n",
            "     BatchNorm2d-159            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-160            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-161            [-1, 512, 2, 2]               0\n",
            "          Conv2d-162           [-1, 1024, 2, 2]         524,288\n",
            "     BatchNorm2d-163           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-164           [-1, 1024, 2, 2]               0\n",
            "       ShakeDrop-165           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-166           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-167            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-168            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-169            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-170            [-1, 512, 2, 2]               0\n",
            "          Conv2d-171            [-1, 512, 2, 2]          73,728\n",
            "     BatchNorm2d-172            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-173            [-1, 512, 2, 2]               0\n",
            "       ShakeDrop-174            [-1, 512, 2, 2]               0\n",
            "          Conv2d-175           [-1, 1024, 2, 2]         524,288\n",
            "     BatchNorm2d-176           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-177           [-1, 1024, 2, 2]               0\n",
            "       ShakeDrop-178           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-179           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-180           [-1, 1024, 2, 2]       1,048,576\n",
            "     BatchNorm2d-181           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-182           [-1, 1024, 2, 2]               0\n",
            "       ShakeDrop-183           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-184           [-1, 1024, 1, 1]         294,912\n",
            "     BatchNorm2d-185           [-1, 1024, 1, 1]           2,048\n",
            "            ReLU-186           [-1, 1024, 1, 1]               0\n",
            "       ShakeDrop-187           [-1, 1024, 1, 1]               0\n",
            "          Conv2d-188           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-189           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-190           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-191           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-192           [-1, 2048, 1, 1]               0\n",
            "       ShakeDrop-193           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-194           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-195           [-1, 1024, 1, 1]       2,097,152\n",
            "     BatchNorm2d-196           [-1, 1024, 1, 1]           2,048\n",
            "            ReLU-197           [-1, 1024, 1, 1]               0\n",
            "       ShakeDrop-198           [-1, 1024, 1, 1]               0\n",
            "          Conv2d-199           [-1, 1024, 1, 1]         294,912\n",
            "     BatchNorm2d-200           [-1, 1024, 1, 1]           2,048\n",
            "            ReLU-201           [-1, 1024, 1, 1]               0\n",
            "       ShakeDrop-202           [-1, 1024, 1, 1]               0\n",
            "          Conv2d-203           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-204           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-205           [-1, 2048, 1, 1]               0\n",
            "       ShakeDrop-206           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-207           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-208           [-1, 1024, 1, 1]       2,097,152\n",
            "     BatchNorm2d-209           [-1, 1024, 1, 1]           2,048\n",
            "            ReLU-210           [-1, 1024, 1, 1]               0\n",
            "       ShakeDrop-211           [-1, 1024, 1, 1]               0\n",
            "          Conv2d-212           [-1, 1024, 1, 1]         294,912\n",
            "     BatchNorm2d-213           [-1, 1024, 1, 1]           2,048\n",
            "            ReLU-214           [-1, 1024, 1, 1]               0\n",
            "       ShakeDrop-215           [-1, 1024, 1, 1]               0\n",
            "          Conv2d-216           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-217           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-218           [-1, 2048, 1, 1]               0\n",
            "       ShakeDrop-219           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-220           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-221           [-1, 2048, 1, 1]               0\n",
            "          Linear-222                 [-1, 1000]       2,049,000\n",
            "          Linear-223                   [-1, 10]          10,010\n",
            "================================================================\n",
            "Total params: 25,038,914\n",
            "Trainable params: 25,038,914\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.29\n",
            "Params size (MB): 95.52\n",
            "Estimated Total Size (MB): 104.82\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "HNT7QPmNfd2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we write the code to train our network "
      ],
      "metadata": {
        "id": "ekXuEGamfe87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = OrderedDict(\n",
        "    lr = [.001],\n",
        "    batch_size = [64],\n",
        "    shuffle = [True],\n",
        "    arch = [\"ResNeXt50\"],\n",
        "    dataset = [\"Cifar10\"],\n",
        "    act_func = [\"ReLU\"],\n",
        "    opt = [\"ADAM\"],\n",
        "    reg = ['shake-drop','dropout','no_reg']\n",
        "\n",
        ")\n",
        "epochs = 30\n",
        "# Number of batches to log from the test data for each test step\n",
        "# (default set low to simplify demo)\n",
        "NUM_BATCHES_TO_LOG = 10 #79\n",
        "\n",
        "# Number of images to log per test batch\n",
        "# (default set low to simplify demo)\n",
        "NUM_IMAGES_PER_BATCH = 32 #128"
      ],
      "metadata": {
        "id": "c9FQtRiQ1bfW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu0NpJOz1bfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e67b4460-8b21-41b3-c86d-8c4345866ab6"
      },
      "source": [
        "m = RunManager()\n",
        "\n",
        "\n",
        "\n",
        "for run in RunBuilder.get_runs(params):\n",
        "    \n",
        "    model = define_model(run.reg)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    if run.act_func == \"Tanh\":\n",
        "        model.relu = nn.Tanh()\n",
        "    \n",
        "    if run.opt == \"ADAM\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=run.lr)\n",
        "    elif run.opt == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=run.lr)\n",
        "    \n",
        "    m.begin_run(run, model, train_loader,val_loader)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        m.begin_epoch()\n",
        "        batch_count = 0\n",
        "        for batch in tqdm(train_loader):\n",
        "            images = batch[0]\n",
        "            labels = batch[1]\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "            loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            m.track_loss(loss)\n",
        "            m.track_num_correct_train(preds, labels)\n",
        "        for batch in tqdm(val_loader):\n",
        "        \n",
        "            images = batch[0]\n",
        "            labels = batch[1]\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "            loss = F.cross_entropy(preds, labels)\n",
        "            m.track_val_loss(loss)\n",
        "            m.track_num_correct_test(preds, labels)\n",
        "        \n",
        "        m.end_epoch()\n",
        "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
        "    for digit in range(10):\n",
        "      columns.append(\"score_\" + str(digit))\n",
        "    test_table = wandb.Table(columns=columns)\n",
        "    log_counter = 0\n",
        "    sum = 0\n",
        "    for batch in test_loader:\n",
        "            \n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        preds = model(images)\n",
        "        _, predicted = torch.max(preds.data, 1)\n",
        "        #loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "        #optimizer.zero_grad()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        if log_counter < NUM_BATCHES_TO_LOG:\n",
        "            log_test_predictions(images, labels, preds, predicted, test_table, log_counter)\n",
        "            log_counter += 1\n",
        "        #m.track_val_loss(loss)\n",
        "        sum += get_num_correct(preds, labels)\n",
        "    print('Test Accuracy is ',sum/len(test_loader.dataset))\n",
        "    wandb.log({\"test_predictions\" : test_table})\n",
        "    m.end_run()\n",
        "\n",
        "# when all runs are done, save results to files\n",
        "m.save('results_resnext_50')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:x4g5e142) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>▁█</td></tr><tr><td>Validation_loss</td><td>█▁</td></tr><tr><td>train_acc</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>0.3363</td></tr><tr><td>Validation_loss</td><td>1.73918</td></tr><tr><td>train_acc</td><td>0.28523</td></tr><tr><td>train_loss</td><td>1.81054</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cool-water-10</strong> at: <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/x4g5e142' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/x4g5e142</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230509_225907-x4g5e142/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:x4g5e142). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230509_230258-jtxw2ds1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl-codes/dl_project_2023/runs/jtxw2ds1' target=\"_blank\">spring-field-11</a></strong> to <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/jtxw2ds1' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/jtxw2ds1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:53<00:00, 11.72it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.1799 train_loss =  2.177720114517212 Validation_acc =  0.2327 Validation_loss =  2.0962597259521485\n",
            "Training Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:51<00:00, 12.05it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 19.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.2717 train_loss =  1.9467999311447144 Validation_acc =  0.3091 Validation_loss =  1.8727615970611573\n",
            "Training Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.96it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.355875 train_loss =  1.7593292214393617 Validation_acc =  0.3801 Validation_loss =  1.7312285411834716\n",
            "Training Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.96it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 19.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.394275 train_loss =  1.6910012221336366 Validation_acc =  0.43 Validation_loss =  1.6269422943115235\n",
            "Training Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 12.01it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.42645 train_loss =  1.622981071472168 Validation_acc =  0.4246 Validation_loss =  1.632246598815918\n",
            "Training Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.95it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.4575 train_loss =  1.540572230529785 Validation_acc =  0.4748 Validation_loss =  1.503621827697754\n",
            "Training Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.98it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.470375 train_loss =  1.5070812030792236 Validation_acc =  0.4814 Validation_loss =  1.508562516784668\n",
            "Training Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.97it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.5029 train_loss =  1.436039855480194 Validation_acc =  0.5007 Validation_loss =  1.4465393573760987\n",
            "Training Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 12.01it/s]\n",
            "100%|██████████| 157/157 [00:08<00:00, 19.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.5019 train_loss =  1.4438335933685302 Validation_acc =  0.5183 Validation_loss =  1.4238096618652343\n",
            "Training Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 12.01it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.525225 train_loss =  1.3735853050231934 Validation_acc =  0.5308 Validation_loss =  1.3694299953460694\n",
            "Training Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.97it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.5338 train_loss =  1.368559093284607 Validation_acc =  0.5137 Validation_loss =  1.4415349536895752\n",
            "Training Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.99it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.539525 train_loss =  1.356070945262909 Validation_acc =  0.5108 Validation_loss =  1.4325160694122314\n",
            "Training Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 12.00it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.540475 train_loss =  1.341331837463379 Validation_acc =  0.5317 Validation_loss =  1.3725143272399902\n",
            "Training Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.94it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.57185 train_loss =  1.2550532181739806 Validation_acc =  0.5588 Validation_loss =  1.323497481918335\n",
            "Training Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:51<00:00, 12.02it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.554475 train_loss =  1.3196617121696472 Validation_acc =  0.5602 Validation_loss =  1.3089748546600342\n",
            "Training Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:52<00:00, 11.96it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 19.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.556725 train_loss =  1.3000564860343933 Validation_acc =  0.5391 Validation_loss =  1.3441268104553223\n",
            "Training Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.34it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.576825 train_loss =  1.2329447996139526 Validation_acc =  0.5718 Validation_loss =  1.2643420307159423\n",
            "Training Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.38it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.5777 train_loss =  1.2360947662353516 Validation_acc =  0.5858 Validation_loss =  1.2427788555145263\n",
            "Training Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.33it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.570175 train_loss =  1.2507279304504395 Validation_acc =  0.5884 Validation_loss =  1.2202148368835448\n",
            "Training Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.26it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.59095 train_loss =  1.1914032103538512 Validation_acc =  0.592 Validation_loss =  1.2006887767791747\n",
            "Training Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:51<00:00, 12.23it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 22.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.597225 train_loss =  1.184981277179718 Validation_acc =  0.584 Validation_loss =  1.2268355979919434\n",
            "Training Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:51<00:00, 12.24it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.588625 train_loss =  1.2024379646301269 Validation_acc =  0.5915 Validation_loss =  1.2168387100219726\n",
            "Training Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:49<00:00, 12.55it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.595775 train_loss =  1.1933336371421814 Validation_acc =  0.5923 Validation_loss =  1.209352518081665\n",
            "Training Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.33it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.582525 train_loss =  1.2236138812065125 Validation_acc =  0.5698 Validation_loss =  1.2646492164611816\n",
            "Training Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.47it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 19.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.60305 train_loss =  1.1686464175224305 Validation_acc =  0.6084 Validation_loss =  1.1750179542541503\n",
            "Training Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.36it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.606875 train_loss =  1.1613135377883912 Validation_acc =  0.5983 Validation_loss =  1.200686729812622\n",
            "Training Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.40it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.616625 train_loss =  1.1286980595588685 Validation_acc =  0.5954 Validation_loss =  1.1938363594055177\n",
            "Training Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.40it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.617125 train_loss =  1.1266733283042907 Validation_acc =  0.6144 Validation_loss =  1.1450969200134278\n",
            "Training Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.29it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.619425 train_loss =  1.1220234268188476 Validation_acc =  0.6104 Validation_loss =  1.1612406295776367\n",
            "Training Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.42it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.619375 train_loss =  1.1231911165237427 Validation_acc =  0.6029 Validation_loss =  1.1910597389221191\n",
            "Test Accuracy is  0.6109\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>▁▂▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██▇██▇██████</td></tr><tr><td>Validation_loss</td><td>█▆▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████▇██████</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>0.6029</td></tr><tr><td>Validation_loss</td><td>1.19106</td></tr><tr><td>train_acc</td><td>0.61938</td></tr><tr><td>train_loss</td><td>1.12319</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">spring-field-11</strong> at: <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/jtxw2ds1' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/jtxw2ds1</a><br/>Synced 5 W&B file(s), 1 media file(s), 321 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230509_230258-jtxw2ds1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230509_233246-woh7eabz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl-codes/dl_project_2023/runs/woh7eabz' target=\"_blank\">frosty-universe-13</a></strong> to <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/woh7eabz' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/woh7eabz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.24it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.434525 train_loss =  1.5875288702011108 Validation_acc =  0.5713 Validation_loss =  1.283604497909546\n",
            "Training Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:46<00:00, 13.30it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.62645 train_loss =  1.1191800189971923 Validation_acc =  0.6571 Validation_loss =  1.0639252502441405\n",
            "Training Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.03it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.683 train_loss =  0.9595637597084046 Validation_acc =  0.6898 Validation_loss =  0.9362650772094726\n",
            "Training Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.99it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.7167 train_loss =  0.864635054063797 Validation_acc =  0.7255 Validation_loss =  0.8393396501541137\n",
            "Training Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.12it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 22.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.7391 train_loss =  0.797849861049652 Validation_acc =  0.7412 Validation_loss =  0.7879155197143555\n",
            "Training Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.23it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.758125 train_loss =  0.7354241150856018 Validation_acc =  0.7502 Validation_loss =  0.7664225603103638\n",
            "Training Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:46<00:00, 13.30it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.764675 train_loss =  0.7148502282142639 Validation_acc =  0.7533 Validation_loss =  0.7507066820144653\n",
            "Training Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 13.00it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.7792 train_loss =  0.6668795952796936 Validation_acc =  0.7608 Validation_loss =  0.7295750431060791\n",
            "Training Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:50<00:00, 12.47it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.715 train_loss =  0.8979135838031769 Validation_acc =  0.7554 Validation_loss =  0.7658767398834229\n",
            "Training Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.89it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.78115 train_loss =  0.6645573882579804 Validation_acc =  0.7684 Validation_loss =  0.7125487154006958\n",
            "Training Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.21it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.7997 train_loss =  0.6022455318450928 Validation_acc =  0.7867 Validation_loss =  0.6607904760360718\n",
            "Training Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 13.02it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.805325 train_loss =  0.5933027693986893 Validation_acc =  0.7632 Validation_loss =  0.7678360853195191\n",
            "Training Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.92it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8024 train_loss =  0.6013687522649765 Validation_acc =  0.7889 Validation_loss =  0.6519127162933349\n",
            "Training Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.95it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.821 train_loss =  0.5405893671989441 Validation_acc =  0.7909 Validation_loss =  0.6588196683883667\n",
            "Training Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.05it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.822825 train_loss =  0.5418148025512696 Validation_acc =  0.7819 Validation_loss =  0.7072151029586792\n",
            "Training Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.12it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8223 train_loss =  0.5450114865541458 Validation_acc =  0.8023 Validation_loss =  0.6306984647750854\n",
            "Training Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.07it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.82845 train_loss =  0.5249066672563553 Validation_acc =  0.8028 Validation_loss =  0.610476683998108\n",
            "Training Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.91it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.84165 train_loss =  0.4745498601436615 Validation_acc =  0.8114 Validation_loss =  0.598658709526062\n",
            "Training Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.96it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.84555 train_loss =  0.46051888406276703 Validation_acc =  0.8145 Validation_loss =  0.5855108661651611\n",
            "Training Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.06it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8489 train_loss =  0.46148912782669066 Validation_acc =  0.7779 Validation_loss =  0.8314081939697265\n",
            "Training Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.16it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 19.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.78895 train_loss =  0.6877693853616714 Validation_acc =  0.8034 Validation_loss =  0.6108939571380615\n",
            "Training Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.93it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.849225 train_loss =  0.4446610690832138 Validation_acc =  0.8221 Validation_loss =  0.5727331039428711\n",
            "Training Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.95it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 25.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8624 train_loss =  0.4063297816991806 Validation_acc =  0.8186 Validation_loss =  0.5852777106285095\n",
            "Training Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.98it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.868425 train_loss =  0.3901225145816803 Validation_acc =  0.8268 Validation_loss =  0.5578573709487915\n",
            "Training Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.07it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.852725 train_loss =  0.4611712307453156 Validation_acc =  0.7708 Validation_loss =  0.761513759803772\n",
            "Training Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.16it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.856375 train_loss =  0.4348095769405365 Validation_acc =  0.8306 Validation_loss =  0.5452764194488525\n",
            "Training Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.89it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8751 train_loss =  0.3740241127252579 Validation_acc =  0.8207 Validation_loss =  0.567519855594635\n",
            "Training Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.86it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8794 train_loss =  0.35838975059986117 Validation_acc =  0.8336 Validation_loss =  0.5529067129135132\n",
            "Training Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:49<00:00, 12.58it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.883825 train_loss =  0.3515893138051033 Validation_acc =  0.8194 Validation_loss =  0.6013593955993652\n",
            "Training Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.18it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.885575 train_loss =  0.34005297683477403 Validation_acc =  0.824 Validation_loss =  0.568721814918518\n",
            "Test Accuracy is  0.8394\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>▁▃▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇███▆█████</td></tr><tr><td>Validation_loss</td><td>█▆▅▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▁▄▂▁▁▁▃▁▁▁▂▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█████</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▃▃▃▄▃▂▂▂▂▂▂▂▂▂▂▃▂▁▁▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>0.824</td></tr><tr><td>Validation_loss</td><td>0.56872</td></tr><tr><td>train_acc</td><td>0.88558</td></tr><tr><td>train_loss</td><td>0.34005</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">frosty-universe-13</strong> at: <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/woh7eabz' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/woh7eabz</a><br/>Synced 5 W&B file(s), 1 media file(s), 321 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230509_233246-woh7eabz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230510_000038-6pwasl3w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl-codes/dl_project_2023/runs/6pwasl3w' target=\"_blank\">honest-leaf-14</a></strong> to <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/6pwasl3w' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/6pwasl3w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.20it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.648675 train_loss =  1.0597473746299744 Validation_acc =  0.7349 Validation_loss =  0.8261746164321899\n",
            "Training Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.05it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.778475 train_loss =  0.691201439523697 Validation_acc =  0.7953 Validation_loss =  0.6457168630599975\n",
            "Training Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.11it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 25.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.810075 train_loss =  0.5848082326889038 Validation_acc =  0.7772 Validation_loss =  0.7314381158828736\n",
            "Training Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.12it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.822475 train_loss =  0.5479366053342819 Validation_acc =  0.7968 Validation_loss =  0.6527726840972901\n",
            "Training Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.11it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.83105 train_loss =  0.5189351506710053 Validation_acc =  0.8187 Validation_loss =  0.5628429191589356\n",
            "Training Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.16it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.856275 train_loss =  0.43267230942249296 Validation_acc =  0.8297 Validation_loss =  0.5523157962799072\n",
            "Training Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.26it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8601 train_loss =  0.43352550210952756 Validation_acc =  0.7287 Validation_loss =  0.9068531982421875\n",
            "Training Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.05it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8245 train_loss =  0.548295137166977 Validation_acc =  0.8316 Validation_loss =  0.5183636838912964\n",
            "Training Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.10it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.879475 train_loss =  0.36429078153371813 Validation_acc =  0.8416 Validation_loss =  0.5155110523223877\n",
            "Training Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.03it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8284 train_loss =  0.5737627374529839 Validation_acc =  0.7502 Validation_loss =  0.8258180747985839\n",
            "Training Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.13it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.855925 train_loss =  0.4364677434206009 Validation_acc =  0.8391 Validation_loss =  0.5031454811096191\n",
            "Training Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.29it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.893325 train_loss =  0.31573843746185304 Validation_acc =  0.8456 Validation_loss =  0.5047836572647094\n",
            "Training Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:46<00:00, 13.30it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.9028 train_loss =  0.28710859128832816 Validation_acc =  0.8405 Validation_loss =  0.5168978359222413\n",
            "Training Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.11it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.88335 train_loss =  0.3862333970844746 Validation_acc =  0.7961 Validation_loss =  0.7359781106948853\n",
            "Training Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.92it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.833025 train_loss =  0.5336550279855728 Validation_acc =  0.8342 Validation_loss =  0.5266728303909302\n",
            "Training Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.05it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.899725 train_loss =  0.3036079083442688 Validation_acc =  0.8461 Validation_loss =  0.5060895617485046\n",
            "Training Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.09it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.896775 train_loss =  0.3304273643136024 Validation_acc =  0.8077 Validation_loss =  0.8245289295196533\n",
            "Training Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.19it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.838375 train_loss =  0.5512863688826561 Validation_acc =  0.8096 Validation_loss =  0.646206657409668\n",
            "Training Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.14it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.88315 train_loss =  0.3580520312070847 Validation_acc =  0.8407 Validation_loss =  0.5693674500465393\n",
            "Training Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 12.94it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 25.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.899175 train_loss =  0.3156321261048317 Validation_acc =  0.8519 Validation_loss =  0.5198390087127686\n",
            "Training Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.10it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.916975 train_loss =  0.25278432568311693 Validation_acc =  0.8533 Validation_loss =  0.5021876836299897\n",
            "Training Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.07it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.930025 train_loss =  0.2029287710785866 Validation_acc =  0.8491 Validation_loss =  0.5275659931182861\n",
            "Training Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.15it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.9379 train_loss =  0.18432008728682994 Validation_acc =  0.8501 Validation_loss =  0.5468801533699036\n",
            "Training Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.19it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.942675 train_loss =  0.167835931918025 Validation_acc =  0.8469 Validation_loss =  0.5512004294395447\n",
            "Training Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.09it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 23.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.943025 train_loss =  0.1693619666069746 Validation_acc =  0.8466 Validation_loss =  0.5275605277061463\n",
            "Training Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.09it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.946275 train_loss =  0.15820967630147934 Validation_acc =  0.8556 Validation_loss =  0.5022565072178841\n",
            "Training Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:48<00:00, 13.01it/s]\n",
            "100%|██████████| 157/157 [00:06<00:00, 24.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.922025 train_loss =  0.38343264195173976 Validation_acc =  0.5411 Validation_loss =  3.2669557136535645\n",
            "Training Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.14it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 22.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.708075 train_loss =  1.093823466682434 Validation_acc =  0.7626 Validation_loss =  0.7719040664672852\n",
            "Training Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:47<00:00, 13.14it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 21.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.857475 train_loss =  0.42696820673942565 Validation_acc =  0.8207 Validation_loss =  0.5934995153427124\n",
            "Training Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:46<00:00, 13.31it/s]\n",
            "100%|██████████| 157/157 [00:07<00:00, 20.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.9092 train_loss =  0.27702557025551794 Validation_acc =  0.8323 Validation_loss =  0.5640857090950012\n",
            "Test Accuracy is  0.8402\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>▅▇▆▇▇▇▅▇█▆███▇██▇▇████████▁▆▇▇</td></tr><tr><td>Validation_loss</td><td>▂▁▂▁▁▁▂▁▁▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁█▂▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▅▆▅▆▇▇▇▅▇▇▅▇▇▇█████▇▂▆▇</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▃▃▄▃▄▃▂▂▃▄▂▂▄▂▂▂▁▁▁▁▁▃█▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>0.8323</td></tr><tr><td>Validation_loss</td><td>0.56409</td></tr><tr><td>train_acc</td><td>0.9092</td></tr><tr><td>train_loss</td><td>0.27703</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">honest-leaf-14</strong> at: <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/6pwasl3w' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/6pwasl3w</a><br/>Synced 5 W&B file(s), 1 media file(s), 321 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230510_000038-6pwasl3w/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
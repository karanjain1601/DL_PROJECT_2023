{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Installs"
      ],
      "metadata": {
        "id": "Ty8YP4TNd3SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s27QlAzX_Qt7",
        "outputId": "2ddd4e44-383f-4378-8489-30f23cc43412"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.22.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPue4B2vPu2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f20fba-6671-4baf-b27d-7e3833c5d38d"
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "import torch.profiler\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "from torchvision import datasets \n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "# calculate train time, writing train data to files etc.\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "import math\n",
        "import copy\n",
        "from IPython.display import clear_output\n",
        "from time import perf_counter\n",
        "from torch.autograd import Variable\n",
        "torch.set_printoptions(linewidth=120)\n",
        "torch.set_grad_enabled(True)     # On by default, leave it here for clarity"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fc89880fd30>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "metadata": {
        "id": "CesBIiQHQYRL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn"
      ],
      "metadata": {
        "id": "y5Av6YqnssFz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "xQOmyV5ruNf9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iDlvtrBQZO3",
        "outputId": "5da15083-6515-4d35-a9a8-10a723564b4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check PyTorch versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n",
            "0.15.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "CojWu8cMDc-j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging into WandB\n"
      ],
      "metadata": {
        "id": "kaAPJzOC_cCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TehLE0Z5_fxY",
        "outputId": "e93fd98d-3962-47b4-944b-57a8aeb7cb9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjain-49\u001b[0m (\u001b[33mdl-codes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset\n"
      ],
      "metadata": {
        "id": "XzxFyYxad71T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "xHh1pvf9eUFw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = torchvision.datasets.CIFAR10('./data', download=True, train=True, transform=train_transforms)\n",
        "\n",
        "# Download and load the test set\n",
        "dataset_test = torchvision.datasets.CIFAR10('./data', download=True, train=False, transform=test_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1262b581-356d-4f26-d575-b2479de35884",
        "id": "ak2BBC1oQpb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, valset = torch.utils.data.random_split(dataset_train, [40000, 10000])\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(dataset_test, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "H_0f-XwTQpb1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set cuda to device"
      ],
      "metadata": {
        "id": "W9gpIza6eIME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.cuda.memory_summary(device=None, abbreviated=True)"
      ],
      "metadata": {
        "id": "i5xtz8_DZBq8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wHJbL98ZY5mg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSi_tn2rOSKl",
        "outputId": "6741ba54-c0ba-441e-fd25-101cfceda948"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Some key definitions"
      ],
      "metadata": {
        "id": "Nsyem3b0eQSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count of correct predictions"
      ],
      "metadata": {
        "id": "8ozaaWJ7eXmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_test_predictions(images, labels, outputs, predicted, test_table, log_counter):\n",
        "  # obtain confidence scores for all classes\n",
        "  scores = F.softmax(outputs.data, dim=1)\n",
        "  log_scores = scores.cpu().numpy()\n",
        "  log_images = images.cpu().numpy()\n",
        "  log_labels = labels.cpu().numpy()\n",
        "  log_preds = predicted.cpu().numpy()\n",
        "  # adding ids based on the order of the images\n",
        "  _id = 0\n",
        "  for i, l, p, s in zip(log_images, log_labels, log_preds, log_scores):\n",
        "    # add required info to data table:\n",
        "    # id, image pixels, model's guess, true label, scores for all classes\n",
        "    img_id = str(_id) + \"_\" + str(log_counter)\n",
        "    test_table.add_data(img_id, wandb.Image(np.transpose(i, (1, 2, 0))), p, l, *s)\n",
        "    _id += 1\n",
        "    if _id == NUM_IMAGES_PER_BATCH:\n",
        "      break\n"
      ],
      "metadata": {
        "id": "87NTgyACpIDd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOe6m7forHCM"
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topk_correct(preds,labels,k=5):\n",
        "    batch_size = preds.shape[0]\n",
        "\n",
        "    # get the top-5 predictions for each sample\n",
        "    topk_values, topk_indices = torch.topk(preds, k=5, dim=1)\n",
        "\n",
        "    # check if the target is in the top-5 predictions\n",
        "    correct_topk = topk_indices.eq(labels.view(-1, 1).expand_as(topk_indices))\n",
        "    return correct_topk\n",
        "## calculate top-5 accuracy\n",
        "#top5_accuracy = correct_topk.float().sum() / batch_size"
      ],
      "metadata": {
        "id": "t6YaB1HBJkyu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## taking value of parameters and trying them in all combinations"
      ],
      "metadata": {
        "id": "jv8d5oYGecI4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBOxsN4A7N8K"
      },
      "source": [
        "# import modules to build RunBuilder and RunManager helper classes\n",
        "from collections  import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "\n",
        "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
        "# combinations of hyper-parameters\n",
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "\n",
        "    Run = namedtuple('Run', params.keys())\n",
        "\n",
        "    runs = []\n",
        "    for v in product(*params.values()):\n",
        "      runs.append(Run(*v))\n",
        "    \n",
        "    return runs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defining Manager class "
      ],
      "metadata": {
        "id": "Zyi8muZXeiMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helps in calculating both train and validation accuracy and losses also help us to maintain a tensorboard and print all the data collected for every epoch and save it in a dataset "
      ],
      "metadata": {
        "id": "DVo1Jq-ge0Oa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSddFGL7zisa"
      },
      "source": [
        "# Helper class, help track loss, accuracy, epoch time, run time, \n",
        "# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n",
        "class RunManager():\n",
        "  def __init__(self):\n",
        "\n",
        "    # tracking every epoch count, loss, accuracy, time\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_val_loss = 0\n",
        "    self.epoch_num_correct_train = 0\n",
        "    self.epoch_num_correct_test = 0\n",
        "    self.epoch_start_time = None\n",
        "\n",
        "    # tracking every run count, run data, hyper-params used, time\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "    self.run_start_time = None\n",
        "\n",
        "    # record model, loader and TensorBoard \n",
        "    self.network = None\n",
        "    self.trainloader = None\n",
        "    self.valloader = None\n",
        "    self.tb = None\n",
        "\n",
        "  # record the count, hyper-param, model, loader of each run\n",
        "  # record sample images and network graph to TensorBoard  \n",
        "  def begin_run(self, run, network, trainloader,valloader):\n",
        "\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.trainloader = trainloader\n",
        "    self.valloader = valloader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    wandb.init(\n",
        "        # set the wandb project where this run will be logged\n",
        "        project=\"dl_project_2023\",\n",
        "        \n",
        "        # track hyperparameters and run metadata\n",
        "        config={\n",
        "        \"learning_rate\": run.lr,\n",
        "        \"architecture\": run.arch,\n",
        "        \"dataset\": run.dataset,\n",
        "        \"epochs\": 30,\n",
        "        \"activation_function\":run.act_func,\n",
        "        \"Optimizer\":run.opt,\n",
        "        \"Regularisation\":run.reg\n",
        "        }\n",
        "    )\n",
        "    #images, labels = next(iter(self.trainloader))\n",
        "    #images, labels = images.to(device), labels.to(device)\n",
        "    #grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "    #self.tb.add_image('images', grid)\n",
        "    #self.tb.add_graph(self.network, images)\n",
        "\n",
        "  # when run ends, close TensorBoard, zero epoch count\n",
        "  def end_run(self):\n",
        "    wandb.finish()\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  # zero epoch count, loss, accuracy, \n",
        "  def begin_epoch(self):\n",
        "    self.epoch_start_time = time.time()\n",
        "\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_val_loss = 0\n",
        "    self.epoch_num_correct_train = 0\n",
        "    self.epoch_num_correct_test = 0\n",
        "    print(\"Training Epoch\",self.epoch_count)\n",
        "\n",
        "  # \n",
        "  def end_epoch(self):\n",
        "    # calculate epoch duration and run duration(accumulate)\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    # record epoch loss and accuracy\n",
        "    train_loss = self.epoch_loss / len(self.trainloader.dataset)\n",
        "    val_loss = self.epoch_val_loss / len(self.valloader.dataset)\n",
        "    train_accuracy = self.epoch_num_correct_train / len(self.trainloader.dataset)\n",
        "    test_accuracy = self.epoch_num_correct_test / len(self.valloader.dataset)\n",
        "    # Record epoch loss and accuracy to TensorBoard \n",
        "    self.tb.add_scalar('Train Loss', train_loss, self.epoch_count)\n",
        "    self.tb.add_scalar('train Accuracy', train_accuracy, self.epoch_count)\n",
        "    self.tb.add_scalar('Validation Loss', val_loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Validation Accuracy', test_accuracy, self.epoch_count)\n",
        "\n",
        "    # Record params to TensorBoard\n",
        "    #for name, param in self.network.named_parameters():\n",
        "      #self.tb.add_histogram(name, param, self.epoch_count)\n",
        "      #self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "    \n",
        "    # Write into 'results' (OrderedDict) for all run related data\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run_count\n",
        "    results[\"epoch\"] = self.epoch_count\n",
        "    results[\"train_loss\"] = train_loss\n",
        "    results[\"val_loss\"] = val_loss\n",
        "    results[\"train_accuracy\"] = train_accuracy\n",
        "    results[\"val_accuracy\"] = test_accuracy\n",
        "    results[\"epoch duration\"] = epoch_duration\n",
        "    results[\"run duration\"] = run_duration\n",
        "    print(\"train_acc = \", train_accuracy, \"train_loss = \", train_loss, \"Validation_acc = \", test_accuracy, \"Validation_loss = \", val_loss)\n",
        "    wandb.log({\"train_acc\": train_accuracy, \"train_loss\": train_loss, \"Validation_acc\": test_accuracy, \"Validation_loss\": val_loss})\n",
        "    \n",
        "    # Record hyper-params into 'results'\n",
        "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "    self.run_data.append(results)\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
        "\n",
        "    # display epoch information and show progress\n",
        "    # clear_output(wait=True)\n",
        "    # display(df)\n",
        "\n",
        "  # accumulate loss of batch into entire epoch loss\n",
        "  def track_loss(self, loss):\n",
        "    # multiply batch size so variety of batch sizes can be compared\n",
        "    self.epoch_loss += loss.item() * self.trainloader.batch_size\n",
        "  def track_val_loss(self, loss):\n",
        "    # multiply batch size so variety of batch sizes can be compared\n",
        "    self.epoch_val_loss += loss.item() * self.valloader.batch_size\n",
        "  # accumulate number of corrects of batch into entire epoch num_correct\n",
        "  def track_num_correct_train(self, preds, labels):\n",
        "    self.epoch_num_correct_train += self._get_num_correct(preds, labels)\n",
        "  def track_num_correct_test(self, preds, labels):\n",
        "    self.epoch_num_correct_test += self._get_num_correct(preds, labels)\n",
        "  @torch.no_grad()\n",
        "  def _get_num_correct(self, preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "  \n",
        "  # save end results of all runs into csv, json for further a\n",
        "  def save(self, fileName):\n",
        "\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data, \n",
        "        orient = 'columns',\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Shake Drop Regularisation\n"
      ],
      "metadata": {
        "id": "74WW3tEuOpjZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cl7bmnHfA8H8"
      },
      "outputs": [],
      "source": [
        "class ShakeDropFunction(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, training=True, p_drop=0.5, alpha_range=[-1, 1]):\n",
        "        if training:\n",
        "            gate = torch.cuda.FloatTensor([0]).bernoulli_(1 - p_drop)\n",
        "            ctx.save_for_backward(gate)\n",
        "            if gate.item() == 0:\n",
        "                alpha = torch.cuda.FloatTensor(x.size(0)).uniform_(*alpha_range)\n",
        "                alpha = alpha.view(alpha.size(0), 1, 1, 1).expand_as(x)\n",
        "                return alpha * x\n",
        "            else:\n",
        "                return x\n",
        "        else:\n",
        "            return (1 - p_drop) * x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        gate = ctx.saved_tensors[0]\n",
        "        if gate.item() == 0:\n",
        "            beta = torch.cuda.FloatTensor(grad_output.size(0)).uniform_(0, 1)\n",
        "            beta = beta.view(beta.size(0), 1, 1, 1).expand_as(grad_output)\n",
        "            beta = Variable(beta)\n",
        "            return beta * grad_output, None, None, None\n",
        "        else:\n",
        "            return grad_output, None, None, None\n",
        "\n",
        "\n",
        "class ShakeDrop(nn.Module):\n",
        "\n",
        "    def __init__(self, p_drop=0.5, alpha_range=[-1, 1]):\n",
        "        super(ShakeDrop, self).__init__()\n",
        "        self.p_drop = p_drop\n",
        "        self.alpha_range = alpha_range\n",
        "\n",
        "    def forward(self, x):\n",
        "        return ShakeDropFunction.apply(x, self.training, self.p_drop, self.alpha_range)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Network as per given Instructions"
      ],
      "metadata": {
        "id": "I7DYL7SCeMWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nothing(x):\n",
        "  return x"
      ],
      "metadata": {
        "id": "yLIzos6Fj4JY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    outchannel_ratio = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, p_shakedrop = 1.0, reg='no_reg'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        if reg == 'shake-drop':\n",
        "            self.drop = ShakeDrop(p_shakedrop)\n",
        "        elif reg == 'dropout':\n",
        "            self.drop = nn.Dropout(p=p_shakedrop)\n",
        "        else:\n",
        "            self.drop = nothing\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.drop(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "            featuremap_size = shortcut.size()[2:4]\n",
        "        else:\n",
        "            shortcut = x\n",
        "            featuremap_size = out.size()[2:4]\n",
        "\n",
        "        batch_size = out.size()[0]\n",
        "        residual_channel = out.size()[1]\n",
        "        shortcut_channel = shortcut.size()[1]\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        if residual_channel != shortcut_channel:\n",
        "            padding = torch.autograd.Variable(\n",
        "                torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0],\n",
        "                                       featuremap_size[1]).fill_(0))\n",
        "            out = out + torch.cat((shortcut, padding), 1)\n",
        "        else:\n",
        "            out = out + shortcut\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    outchannel_ratio = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None,p_shakedrop=1.0, reg='no_reg'):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, (planes * 1), kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d((planes * 1))\n",
        "        self.conv3 = nn.Conv2d((planes * 1), planes * Bottleneck.outchannel_ratio, kernel_size=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(planes * Bottleneck.outchannel_ratio)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        if reg == 'shake-drop':\n",
        "            self.drop = ShakeDrop(p_shakedrop)\n",
        "        elif reg == 'dropout':\n",
        "            self.drop = nn.Dropout(p=p_shakedrop)\n",
        "        else:\n",
        "            self.drop = nothing\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        out = self.bn4(out)\n",
        "\n",
        "        out = self.drop(out)\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "            featuremap_size = shortcut.size()[2:4]\n",
        "        else:\n",
        "            shortcut = x\n",
        "            featuremap_size = out.size()[2:4]\n",
        "\n",
        "        batch_size = out.size()[0]\n",
        "        residual_channel = out.size()[1]\n",
        "        shortcut_channel = shortcut.size()[1]\n",
        "\n",
        "        if residual_channel != shortcut_channel:\n",
        "            padding = torch.autograd.Variable(\n",
        "                torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0],\n",
        "                                       featuremap_size[1]).fill_(0))\n",
        "            out += torch.cat((shortcut, padding), 1)\n",
        "        else:\n",
        "            out += shortcut\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class PyramidNet_ShakeDrop(nn.Module):\n",
        "\n",
        "    def __init__(self, depth, alpha, num_classes, bottleneck=False, reg='no_reg'):\n",
        "        super(PyramidNet_ShakeDrop, self).__init__()\n",
        "        blocks = {18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n",
        "        layers_list = {18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3],\n",
        "                  200: [3, 24, 36, 3]}\n",
        "\n",
        "        if layers_list.get(depth) is None:\n",
        "            if bottleneck == True:\n",
        "                blocks[depth] = Bottleneck\n",
        "                temp_cfg = int((depth - 2) / 12)\n",
        "            else:\n",
        "                blocks[depth] = BasicBlock\n",
        "                temp_cfg = int((depth - 2) / 8)\n",
        "\n",
        "            layers_list[depth] = [temp_cfg, temp_cfg, temp_cfg, temp_cfg]\n",
        "            print('=> the layer configuration for each stage is set to', layers_list[depth])\n",
        "\n",
        "        # self.u_idx is the index of self.p_drop\n",
        "        # self.p_drop is initialized to an geometric sequence, also can refer to the parameter setting method in the paper\n",
        "        self.u_idx = 0\n",
        "        all_depth = sum(layers_list[depth])\n",
        "        self.p_drop = [0.5/all_depth * (i + 1) for i in range(all_depth)]\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.addrate = alpha / (sum(layers_list[depth]) * 1.0)\n",
        "\n",
        "        self.input_featuremap_dim = self.inplanes\n",
        "        # down1\n",
        "        self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # down2\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.featuremap_dim = self.input_featuremap_dim\n",
        "        self.layer1 = self.pyramidal_make_layer(blocks[depth], layers_list[depth][0],reg=reg)\n",
        "        # down 3,4,5\n",
        "        self.layer2 = self.pyramidal_make_layer(blocks[depth], layers_list[depth][1], stride=2, reg=reg)\n",
        "        self.layer3 = self.pyramidal_make_layer(blocks[depth], layers_list[depth][2], stride=2, reg=reg)\n",
        "        self.layer4 = self.pyramidal_make_layer(blocks[depth], layers_list[depth][3], stride=2, reg=reg)\n",
        "\n",
        "        self.final_featuremap_dim = self.input_featuremap_dim\n",
        "        self.bn_final = nn.BatchNorm2d(self.final_featuremap_dim)\n",
        "        self.relu_final = nn.ReLU(inplace=True)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def pyramidal_make_layer(self, block, block_depth, stride=1, reg='no_reg'):\n",
        "        downsample = None\n",
        "        if stride != 1:  # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\n",
        "            downsample = nn.AvgPool2d((2, 2), stride=(2, 2), ceil_mode=True)\n",
        "\n",
        "        layers = []\n",
        "        self.featuremap_dim = self.featuremap_dim + self.addrate\n",
        "        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample,self.p_drop[self.u_idx],reg=reg))\n",
        "        self.u_idx += 1\n",
        "        for i in range(1, block_depth):\n",
        "            temp_featuremap_dim = self.featuremap_dim + self.addrate\n",
        "            layers.append(\n",
        "                block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1, None,self.p_drop[self.u_idx]))\n",
        "            self.u_idx += 1\n",
        "            self.featuremap_dim = temp_featuremap_dim\n",
        "        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.bn_final(x)\n",
        "        x = self.relu_final(x)\n",
        "        # x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "PJgnbwgeCgHG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "HNT7QPmNfd2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we write the code to train our network "
      ],
      "metadata": {
        "id": "ekXuEGamfe87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = OrderedDict(\n",
        "    lr = [.001],\n",
        "    batch_size = [64],\n",
        "    shuffle = [True],\n",
        "    arch = [\"pyramidNet-110\"],\n",
        "    dataset = [\"Cifar10\"],\n",
        "    act_func = [\"ReLU\"],\n",
        "    opt = [\"ADAM\"],\n",
        "    reg = ['no_reg']\n",
        "\n",
        ")\n",
        "epochs = 30\n",
        "# Number of batches to log from the test data for each test step\n",
        "# (default set low to simplify demo)\n",
        "NUM_BATCHES_TO_LOG = 10 #79\n",
        "\n",
        "# Number of images to log per test batch\n",
        "# (default set low to simplify demo)\n",
        "NUM_IMAGES_PER_BATCH = 32 #128"
      ],
      "metadata": {
        "id": "c9FQtRiQ1bfW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu0NpJOz1bfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30059e57-566d-4aa4-e751-6c46c6d4da14"
      },
      "source": [
        "m = RunManager()\n",
        "\n",
        "\n",
        "\n",
        "for run in RunBuilder.get_runs(params):\n",
        "    \n",
        "    model = PyramidNet_ShakeDrop(depth=110, alpha=270, num_classes=10, reg=run.reg).to(device)\n",
        "    \n",
        "    if run.act_func == \"Tanh\":\n",
        "        model.relu = nn.Tanh()\n",
        "    \n",
        "    if run.opt == \"ADAM\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=run.lr)\n",
        "    elif run.opt == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=run.lr)\n",
        "    \n",
        "    m.begin_run(run, model, train_loader,val_loader)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        m.begin_epoch()\n",
        "        batch_count = 0\n",
        "        for batch in tqdm(train_loader):\n",
        "            images = batch[0]\n",
        "            labels = batch[1]\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "            loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            m.track_loss(loss)\n",
        "            m.track_num_correct_train(preds, labels)\n",
        "        for batch in tqdm(val_loader):\n",
        "        \n",
        "            images = batch[0]\n",
        "            labels = batch[1]\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "            loss = F.cross_entropy(preds, labels)\n",
        "            m.track_val_loss(loss)\n",
        "            m.track_num_correct_test(preds, labels)\n",
        "        \n",
        "        m.end_epoch()\n",
        "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
        "    for digit in range(10):\n",
        "      columns.append(\"score_\" + str(digit))\n",
        "    test_table = wandb.Table(columns=columns)\n",
        "    log_counter = 0\n",
        "    sum = 0\n",
        "    for batch in test_loader:\n",
        "            \n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        preds = model(images)\n",
        "        _, predicted = torch.max(preds.data, 1)\n",
        "        #loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "        #optimizer.zero_grad()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        if log_counter < NUM_BATCHES_TO_LOG:\n",
        "            log_test_predictions(images, labels, preds, predicted, test_table, log_counter)\n",
        "            log_counter += 1\n",
        "        #m.track_val_loss(loss)\n",
        "        sum += get_num_correct(preds, labels)\n",
        "    print('Test Accuracy is ',sum/len(test_loader.dataset))\n",
        "    wandb.log({\"test_predictions\" : test_table})\n",
        "    m.end_run()\n",
        "\n",
        "# when all runs are done, save results to files\n",
        "m.save('results_pyramidNet-110')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> the layer configuration for each stage is set to [13, 13, 13, 13]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230510_010306-2anw5vy6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl-codes/dl_project_2023/runs/2anw5vy6' target=\"_blank\">desert-voice-21</a></strong> to <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dl-codes/dl_project_2023' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/2anw5vy6' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/2anw5vy6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:22<00:00,  7.57it/s]\n",
            "100%|██████████| 157/157 [00:11<00:00, 13.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.43335 train_loss =  1.531969150352478 Validation_acc =  0.5417 Validation_loss =  1.2956554885864258\n",
            "Training Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:15<00:00,  8.23it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.563025 train_loss =  1.2165741435050965 Validation_acc =  0.5856 Validation_loss =  1.148620985031128\n",
            "Training Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.21it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.623075 train_loss =  1.0603084952354431 Validation_acc =  0.645 Validation_loss =  1.0119662986755371\n",
            "Training Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.20it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.656125 train_loss =  0.9688712270736695 Validation_acc =  0.658 Validation_loss =  0.9702641265869141\n",
            "Training Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.06it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.6851 train_loss =  0.8865883378982544 Validation_acc =  0.6803 Validation_loss =  0.9256631664276123\n",
            "Training Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.08it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.7121 train_loss =  0.823015775346756 Validation_acc =  0.6976 Validation_loss =  0.8800731029510498\n",
            "Training Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.16it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.7266 train_loss =  0.7812681471824646 Validation_acc =  0.7176 Validation_loss =  0.8201358757019043\n",
            "Training Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.10it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.74695 train_loss =  0.7268459597587585 Validation_acc =  0.7385 Validation_loss =  0.7543968898773193\n",
            "Training Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.17it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.75665 train_loss =  0.6961486475944519 Validation_acc =  0.747 Validation_loss =  0.7399469190597534\n",
            "Training Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.15it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.771625 train_loss =  0.6579803993701935 Validation_acc =  0.7452 Validation_loss =  0.7310082838058471\n",
            "Training Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.14it/s]\n",
            "100%|██████████| 157/157 [00:08<00:00, 17.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.780625 train_loss =  0.6277419713497162 Validation_acc =  0.7566 Validation_loss =  0.6857312526702881\n",
            "Training Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:18<00:00,  7.96it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.7917 train_loss =  0.5995524851799011 Validation_acc =  0.7579 Validation_loss =  0.6990051643371582\n",
            "Training Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.08it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.800975 train_loss =  0.5719713004112243 Validation_acc =  0.7712 Validation_loss =  0.6686800249099731\n",
            "Training Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.17it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.809325 train_loss =  0.5477824558019638 Validation_acc =  0.778 Validation_loss =  0.6506284969329834\n",
            "Training Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.07it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8172 train_loss =  0.5237782398462295 Validation_acc =  0.7863 Validation_loss =  0.6442580610275268\n",
            "Training Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.11it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.82555 train_loss =  0.5010282725572586 Validation_acc =  0.7894 Validation_loss =  0.6439917921066284\n",
            "Training Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.04it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8327 train_loss =  0.47544955549240114 Validation_acc =  0.7881 Validation_loss =  0.6412973476409912\n",
            "Training Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.11it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.83935 train_loss =  0.45521555731296537 Validation_acc =  0.7913 Validation_loss =  0.6277735410690307\n",
            "Training Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.12it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 17.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.845975 train_loss =  0.4373030364990234 Validation_acc =  0.7948 Validation_loss =  0.6211263790130616\n",
            "Training Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.08it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8519 train_loss =  0.41919255430698393 Validation_acc =  0.7965 Validation_loss =  0.6137593301773071\n",
            "Training Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.16it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.85915 train_loss =  0.3982013435125351 Validation_acc =  0.7972 Validation_loss =  0.6101214298248291\n",
            "Training Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.20it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8687 train_loss =  0.3775002766609192 Validation_acc =  0.7971 Validation_loss =  0.6216071944236755\n",
            "Training Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.04it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.869225 train_loss =  0.3694258712053299 Validation_acc =  0.7998 Validation_loss =  0.6109344976425171\n",
            "Training Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.12it/s]\n",
            "100%|██████████| 157/157 [00:08<00:00, 17.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.87695 train_loss =  0.34990265072584154 Validation_acc =  0.8055 Validation_loss =  0.6208705726623536\n",
            "Training Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.21it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.8836 train_loss =  0.33091447983980177 Validation_acc =  0.8069 Validation_loss =  0.6114471891403198\n",
            "Training Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.17it/s]\n",
            "100%|██████████| 157/157 [00:08<00:00, 17.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.88775 train_loss =  0.31370515636205676 Validation_acc =  0.8065 Validation_loss =  0.6155231611251831\n",
            "Training Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.15it/s]\n",
            "100%|██████████| 157/157 [00:10<00:00, 15.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.892475 train_loss =  0.29909084376096723 Validation_acc =  0.8051 Validation_loss =  0.613045493888855\n",
            "Training Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:17<00:00,  8.10it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.901025 train_loss =  0.28333294730186465 Validation_acc =  0.8126 Validation_loss =  0.6099747633934021\n",
            "Training Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.13it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 16.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.904 train_loss =  0.27119221777915953 Validation_acc =  0.8078 Validation_loss =  0.6133622520446778\n",
            "Training Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [01:16<00:00,  8.16it/s]\n",
            "100%|██████████| 157/157 [00:09<00:00, 15.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc =  0.906875 train_loss =  0.2568976892113686 Validation_acc =  0.8083 Validation_loss =  0.6218654453277588\n",
            "Test Accuracy is  0.8218\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>▁▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Validation_loss</td><td>█▆▅▅▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Validation_acc</td><td>0.8083</td></tr><tr><td>Validation_loss</td><td>0.62187</td></tr><tr><td>train_acc</td><td>0.90687</td></tr><tr><td>train_loss</td><td>0.2569</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">desert-voice-21</strong> at: <a href='https://wandb.ai/dl-codes/dl_project_2023/runs/2anw5vy6' target=\"_blank\">https://wandb.ai/dl-codes/dl_project_2023/runs/2anw5vy6</a><br/>Synced 5 W&B file(s), 1 media file(s), 321 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230510_010306-2anw5vy6/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}